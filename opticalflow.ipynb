{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20400"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "data_path = \"./data/\"\n",
    "train_file = \"{}train/train.mp4\".format(data_path)\n",
    "test_file = \"{}test/test.mp4\".format(data_path)\n",
    "labels = [float(speed) for speed in open(\"{}train/train.txt\".format(data_path))]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChangeBrightness(image):\n",
    "    bright_factor = 0.2 + np.random.uniform()\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    # perform brightness augmentation only on the second channel\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2] * bright_factor\n",
    "    \n",
    "    # change back to RGB\n",
    "    image_rgb = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return image_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a bunch of frames out of a video\n",
    "def CreateFrames(fname, outdir):\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    success, img = cap.read()\n",
    "    currentFrame = 0\n",
    "    while success:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # crop image to remove dash and make 256 x 256\n",
    "        img = img[114:370, 192:-192]\n",
    "        cv2.imwrite(\"%s%d.jpg\" % (outdir, currentFrame), img)\n",
    "        success, img = cap.read()\n",
    "        currentFrame += 1\n",
    "    cap.release()\n",
    "    \n",
    "#CreateFrames(train_file, \"data/train/\")\n",
    "#CreateFrames(test_file, \"data/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing around with images\n",
    "# image shape (140, 400, 3)\n",
    "#img = cv2.imread(\"./data/train/1223.jpg\")\n",
    "#cv2.imshow('img', img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "#img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTrainData(fnames, speeds):\n",
    "    d = {\"image_path\":fnames, \"speed\":speeds}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df\n",
    "    \n",
    "train_fnames = [\"%strain/%d.jpg\" % (data_path, i) for i in range(len(labels))]\n",
    "train_df = CreateTrainData(train_fnames, labels)\n",
    "#train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_shuffle(df):\n",
    "    train_data = pd.DataFrame()\n",
    "    valid_data = pd.DataFrame()\n",
    "    for i in range(len(df) - 1):\n",
    "        idx1 = np.random.randint(len(df) - 1)\n",
    "        idx2 = idx1 + 1\n",
    "        \n",
    "        row1 = df.iloc[[idx1]].reset_index()\n",
    "        row2 = df.iloc[[idx2]].reset_index()\n",
    "        \n",
    "        randInt = np.random.randint(9)\n",
    "        if randInt < 2:\n",
    "            valid_frames = [valid_data, row1, row2]\n",
    "            valid_data = pd.concat(valid_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "        else:\n",
    "            train_frames = [train_data, row1, row2]\n",
    "            train_data = pd.concat(train_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "    return train_data, valid_data\n",
    "train_data, val_data = batch_shuffle(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetOpticalFlow(img1, img2):\n",
    "    gray1, gray2 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY), cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    hsv = np.zeros_like(img1)\n",
    "    hsv[...,1] = 255\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    return bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, train=False):\n",
    "    image = cv2.resize(image, (220, 66), interpolation = cv2.INTER_AREA)\n",
    "    if train:\n",
    "        image = ChangeBrightness(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes training data is shuffled\n",
    "def generate_data(data, batch_size = 32, train=True):\n",
    "    image_batch = np.zeros((batch_size, 3, 66, 220))\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    data_len = len(data.index)\n",
    "    cur = 0\n",
    "    while cur * batch_size < data_len:\n",
    "        start_idx = cur * batch_size\n",
    "        \n",
    "        # validation data isn't shuffled and we can iterate frame by frame\n",
    "        step = 2 if train else 1\n",
    "        for i, j in enumerate(range(start_idx, min(start_idx + batch_size, data_len-2), step)):\n",
    "            row1 = data.iloc[j]\n",
    "            row2 = data.iloc[j + 1]\n",
    "            \n",
    "            # get flow data\n",
    "            img1 = preprocess_image(cv2.imread(row1['image_path']), train)\n",
    "            img2 = preprocess_image(cv2.imread(row2['image_path']), train)\n",
    "            flow = GetOpticalFlow(img1, img2)\n",
    "            f = flow\n",
    "            flow = np.transpose(flow, (2, 0, 1))\n",
    "            \n",
    "            # add gaussian noise\n",
    "            speed = np.mean([row1['speed'], row2['speed']])\n",
    "            \n",
    "            # add noise when the car is moving\n",
    "            if train and not speed:\n",
    "                speed += np.random.normal()\n",
    "            \n",
    "            image_batch[i] = flow\n",
    "            label_batch[i] = speed\n",
    "            \n",
    "        cur += 1\n",
    "        if train: image_batch, label_batch = shuffle(image_batch, label_batch)\n",
    "        x, y = torch.from_numpy(image_batch).type(torch.cuda.FloatTensor), torch.from_numpy(label_batch).type(torch.cuda.FloatTensor)\n",
    "        yield x, f, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class FlowModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FlowModel, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "        nn.Conv2d(3, 24, 5, 2),\n",
    "        nn.ELU(),\n",
    "        nn.Conv2d(24, 36, 5, 2),\n",
    "        nn.ELU(),\n",
    "        nn.Conv2d(36, 48, 5, 2),\n",
    "        nn.ELU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Conv2d(48, 64, 3),\n",
    "        nn.ELU(),\n",
    "        nn.Conv2d(64, 64, 3),\n",
    "        nn.ELU(),\n",
    "        Flatten(),\n",
    "        nn.Linear(1280, 100),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(100, 50),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(50, 10),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(10, 1))\n",
    "        \n",
    "        # initialize weights\n",
    "        self.model.apply(self.init_weights)\n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # normalize values\n",
    "        x = x / 127.5 - 1\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dl, opt):\n",
    "    criterion = nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    n_batches = 0\n",
    "    for batch_img, _, batch_label in dl:\n",
    "        batch_img.cuda()\n",
    "        model.zero_grad()\n",
    "        batch_preds = model(batch_img)\n",
    "        loss = criterion(batch_preds.squeeze(), batch_label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "        \n",
    "    return total_loss / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_validation_loss(model, val_dl):\n",
    "    n_batches = 0\n",
    "    total_loss = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    for batch_img, _, batch_label in val_dl:\n",
    "        batch_img.cuda()\n",
    "        batch_preds = model(batch_img)\n",
    "        loss = criterion(batch_preds.squeeze(), batch_label)\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "    return total_loss / n_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find fastest batch size\n",
    "#for i in range(10):\n",
    "#    t0 = time.time()\n",
    "#    bs = 2**i\n",
    "#    dl = generate_training_data(train_data, batch_size=bs)\n",
    "#    train_epoch(model, dl, opt)\n",
    "#    t1 = time.time()\n",
    "#    diff = t1 - t0\n",
    "#    print('Batch size: {}, training time: {}'.format(bs, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = FlowModel().to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.07201549905021826, val_loss: 0.221366369475921\n",
      "train_loss: 0.0640717149381676, val_loss: 0.4499005331761307\n",
      "train_loss: 0.060312867630273104, val_loss: 0.3239288433558411\n",
      "train_loss: 0.052340716769498204, val_loss: 0.059685288928449154\n",
      "train_loss: 0.04713526691850876, val_loss: 0.9183496079511113\n",
      "train_loss: 0.04865508956173735, val_loss: 0.18647991079423162\n",
      "train_loss: 0.043256443053964644, val_loss: 0.1256821695715189\n",
      "train_loss: 0.041401834843019326, val_loss: 0.198995320747296\n",
      "train_loss: 0.04087931484795145, val_loss: 0.06625465096698867\n",
      "train_loss: 0.037060855549850294, val_loss: 0.03351790871885088\n",
      "train_loss: 0.03580085797265412, val_loss: 0.2833390376634068\n",
      "train_loss: 0.03627995131236891, val_loss: 0.03222635419418415\n",
      "train_loss: 0.03410981422770889, val_loss: 0.020948538789525628\n",
      "train_loss: 89.97017744512507, val_loss: 0.03353218770482474\n",
      "train_loss: 0.034400050062686205, val_loss: 0.02469432669588261\n",
      "train_loss: 8.088705794480179, val_loss: 0.40474578448467785\n",
      "train_loss: 0.0990362464555449, val_loss: 0.847705616719193\n",
      "train_loss: 0.042943225069452196, val_loss: 0.602403043044938\n",
      "train_loss: 27.135940250505, val_loss: 0.9141038689348433\n",
      "train_loss: 3576.6686768801806, val_loss: 0.37425504210922456\n",
      "train_loss: 0.05404010506707334, val_loss: 0.02927067133391069\n",
      "train_loss: 0.03687447817215035, val_loss: 0.027865541038206883\n",
      "train_loss: 0.03386366781928847, val_loss: 0.0765644202215804\n",
      "train_loss: 0.03289840742945671, val_loss: 0.02346548122457332\n",
      "train_loss: 0.04206351180290503, val_loss: 0.18097243830561638\n",
      "train_loss: 0.8113753667642032, val_loss: 0.23961050146155888\n",
      "train_loss: 0.0370096130251524, val_loss: 98.63769902345828\n",
      "train_loss: 0.033210764766760895, val_loss: 0.02547106061441203\n",
      "train_loss: 0.03090572384967198, val_loss: 0.05637693032622337\n",
      "train_loss: 0.030084745162316868, val_loss: 5157.581882052951\n",
      "train_loss: 58.06616211855303, val_loss: 0.0348731715283874\n",
      "train_loss: 0.029911927706111344, val_loss: 0.04932233722259601\n",
      "train_loss: 0.029919040359316335, val_loss: 0.022586904116906226\n",
      "train_loss: 0.02932607551525918, val_loss: 0.023694531759247184\n",
      "train_loss: 0.036609233041564306, val_loss: 0.5910468589928415\n",
      "train_loss: 8947.055506868235, val_loss: 0.34471430215570664\n",
      "train_loss: 0.04060138378953261, val_loss: 0.01812113480021556\n",
      "train_loss: 0.030395546000480892, val_loss: 0.053922269545081586\n",
      "train_loss: 0.028221188541201335, val_loss: 0.0318535670845045\n",
      "train_loss: 0.03447548691709075, val_loss: 0.031166678682590526\n",
      "train_loss: 0.026606403448949417, val_loss: 0.3746620785031054\n",
      "train_loss: 0.028636875333294513, val_loss: 0.1172312983415193\n",
      "train_loss: 0.026717992187778074, val_loss: 0.03579826978966594\n",
      "train_loss: 28.118024981520588, val_loss: 0.04038851035551892\n",
      "train_loss: 0.026855111047024687, val_loss: 0.016007645133261878\n",
      "train_loss: 0.02552428765357622, val_loss: 0.052024762663576335\n",
      "train_loss: 6.626246723962287, val_loss: 0.034834118404736124\n",
      "train_loss: 0.02705987704346978, val_loss: 0.1759840953681204\n",
      "train_loss: 138.0790418223027, val_loss: 0.2950909961428907\n",
      "train_loss: 0.02984223283466793, val_loss: 0.05737842955730028\n",
      "train_loss: 0.025254835359632008, val_loss: 0.02450229779868904\n",
      "train_loss: 0.024884243206601712, val_loss: 0.09145405164195432\n",
      "train_loss: 0.02665433024747237, val_loss: 0.020703435513294406\n",
      "train_loss: 0.024687122140500332, val_loss: 0.03500001903416382\n",
      "train_loss: 0.02424178058056221, val_loss: 0.014116790753582286\n",
      "train_loss: 0.024354508954040226, val_loss: 0.015527243053333627\n",
      "train_loss: 0.023160461925961558, val_loss: 0.1582476556715038\n",
      "train_loss: 0.022664053801206813, val_loss: 0.01345125615545031\n",
      "train_loss: 0.023169295220155147, val_loss: 0.5749163197146522\n",
      "train_loss: 0.027314590699520084, val_loss: 0.038277723309066564\n",
      "train_loss: 0.0225867337111624, val_loss: 0.15920033554236093\n",
      "train_loss: 0.02411143252656104, val_loss: 0.012654312051987896\n",
      "train_loss: 0.022585472764237034, val_loss: 0.014705328930479785\n",
      "train_loss: 0.022567387700321212, val_loss: 0.014274747524824407\n",
      "train_loss: 0.02250127825931075, val_loss: 0.01742041637448387\n",
      "train_loss: 0.020962985544165057, val_loss: 0.01093066548411217\n",
      "train_loss: 0.0589685040909136, val_loss: 0.21205887467496926\n",
      "train_loss: 0.02823879789455884, val_loss: 0.03293715254403651\n",
      "train_loss: 0.021815626367536044, val_loss: 0.010403876684399115\n",
      "train_loss: 0.17744486584072752, val_loss: 0.11151879549854332\n",
      "train_loss: 0.024910766826642138, val_loss: 0.01662619528360665\n",
      "train_loss: 0.022154602796710547, val_loss: 0.01784861116256151\n",
      "train_loss: 0.020952323357754897, val_loss: 0.11816882807761431\n",
      "train_loss: 0.02241024434671647, val_loss: 0.017265693116415706\n",
      "train_loss: 0.0220927391802111, val_loss: 0.020824717344819672\n",
      "train_loss: 0.021724330231307015, val_loss: 0.01646701256848044\n",
      "train_loss: 0.020822482814471566, val_loss: 0.5633588913414214\n",
      "train_loss: 0.02630306869715212, val_loss: 0.0119360277765534\n",
      "train_loss: 68482.14074494349, val_loss: 0.3062079855137401\n",
      "train_loss: 798.5343040386065, val_loss: 0.05347386271589332\n",
      "train_loss: 0.025672508644000176, val_loss: 0.07013879162776801\n",
      "train_loss: 0.022821597480815987, val_loss: 0.020948560572125845\n",
      "train_loss: 0.020192845454139095, val_loss: 0.07061753577242295\n",
      "train_loss: 308.6969024920911, val_loss: 0.02128800550579197\n",
      "train_loss: 0.019535614729618594, val_loss: 0.024799188392029867\n",
      "train_loss: 0.02026617044072238, val_loss: 0.011843914670559267\n",
      "train_loss: 0.025304475836756248, val_loss: 0.03792255433897177\n",
      "train_loss: 0.02216194179134383, val_loss: 0.027273821411654353\n",
      "train_loss: 0.021108048566196476, val_loss: 0.012566507729287777\n",
      "train_loss: 0.019604852325433204, val_loss: 0.01020417894081523\n",
      "train_loss: 0.019013364416276737, val_loss: 0.2459595719507585\n",
      "train_loss: 0.037492354036188655, val_loss: 0.05125393537390563\n",
      "train_loss: 0.02461590162373238, val_loss: 0.06485979491844773\n",
      "train_loss: 0.024517615543558233, val_loss: 0.01730708623977585\n",
      "train_loss: 1024.0018537652777, val_loss: 0.2398676752216286\n",
      "train_loss: 0.03956026426186004, val_loss: 0.012680396457047513\n",
      "train_loss: 56.131316473249406, val_loss: 0.046793070466568075\n",
      "train_loss: 0.022944778932498827, val_loss: 0.1673893282810847\n",
      "train_loss: 0.031469276449042224, val_loss: 0.02796297802382873\n",
      "train_loss: 0.021354381584622446, val_loss: 0.22822262553705108\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    dl = generate_data(train_data, batch_size=bs)\n",
    "    val_dl = generate_data(val_data, batch_size=bs, train=False)\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    train_loss = train_epoch(model, dl, opt) / bs\n",
    "    \n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    val_loss = calculate_validation_loss(model, val_dl) / bs\n",
    "    print('train_loss: {}, val_loss: {}'.format(train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlowModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 24, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Conv2d(24, 36, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (3): ELU(alpha=1.0)\n",
       "    (4): Conv2d(36, 48, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (5): ELU(alpha=1.0)\n",
       "    (6): Dropout(p=0.5)\n",
       "    (7): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (8): ELU(alpha=1.0)\n",
       "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (10): ELU(alpha=1.0)\n",
       "    (11): Flatten()\n",
       "    (12): Linear(in_features=1280, out_features=100, bias=True)\n",
       "    (13): ELU(alpha=1.0)\n",
       "    (14): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (15): ELU(alpha=1.0)\n",
       "    (16): Linear(in_features=50, out_features=10, bias=True)\n",
       "    (17): ELU(alpha=1.0)\n",
       "    (18): Linear(in_features=10, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "model_path = '{}flow_model'.format(data_path)\n",
    "torch.save(model.state_dict(), model_path)\n",
    "model = FlowModel()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
