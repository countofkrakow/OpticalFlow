{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20400"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "data_path = \"./data/\"\n",
    "train_file = \"{}train/train.mp4\".format(data_path)\n",
    "test_file = \"{}test/test.mp4\".format(data_path)\n",
    "labels = [float(speed) for speed in open(\"{}train/train.txt\".format(data_path))]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChangeBrightness(image):\n",
    "    bright_factor = 0.2 + np.random.uniform()\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    # perform brightness augmentation only on the second channel\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2] * bright_factor\n",
    "    \n",
    "    # change back to RGB\n",
    "    image_rgb = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return image_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a bunch of frames out of a video\n",
    "def CreateFrames(fname, outdir):\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    success, img = cap.read()\n",
    "    currentFrame = 0\n",
    "    while success:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # crop image to remove dash and make 256 x 256\n",
    "        img = crop(img)\n",
    "        cv2.imwrite(\"%s%d.jpg\" % (outdir, currentFrame), img)\n",
    "        success, img = cap.read()\n",
    "        currentFrame += 1\n",
    "    cap.release()\n",
    "    \n",
    "#CreateFrames(train_file, \"data/train/\")\n",
    "#CreateFrames(test_file, \"data/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img): return img[114:370, 192:-192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTrainData(fnames, speeds):\n",
    "    d = {\"image_path\":fnames, \"speed\":speeds}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df\n",
    "    \n",
    "train_fnames = [\"%strain/%d.jpg\" % (data_path, i) for i in range(len(labels))]\n",
    "train_df = CreateTrainData(train_fnames, labels)\n",
    "#train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_shuffle(df):\n",
    "    train_data = pd.DataFrame()\n",
    "    valid_data = pd.DataFrame()\n",
    "    for i in range(len(df) - 1):\n",
    "        idx1 = np.random.randint(len(df) - 1)\n",
    "        idx2 = idx1 + 1\n",
    "        \n",
    "        row1 = df.iloc[[idx1]].reset_index()\n",
    "        row2 = df.iloc[[idx2]].reset_index()\n",
    "        \n",
    "        randInt = np.random.randint(9)\n",
    "        if randInt < 2:\n",
    "            valid_frames = [valid_data, row1, row2]\n",
    "            valid_data = pd.concat(valid_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "        else:\n",
    "            train_frames = [train_data, row1, row2]\n",
    "            train_data = pd.concat(train_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "    return train_data, valid_data\n",
    "train_data, val_data = batch_shuffle(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetOpticalFlow(img1, img2):\n",
    "    gray1, gray2 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY), cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    hsv = np.zeros_like(img1)\n",
    "    hsv[...,1] = 255\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    return bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, train=False):\n",
    "    image = cv2.resize(image, (220, 66), interpolation = cv2.INTER_AREA)\n",
    "    if train:\n",
    "        image = ChangeBrightness(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes training data is shuffled\n",
    "def generate_data(data, batch_size = 32, train=True):\n",
    "    image_batch = np.zeros((batch_size, 3, 66, 220))\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    data_len = len(data.index)\n",
    "    cur = 0\n",
    "    while cur * batch_size < data_len:\n",
    "        start_idx = cur * batch_size\n",
    "        \n",
    "        # validation data isn't shuffled and we can iterate frame by frame\n",
    "        step = 2 if train else 1\n",
    "        for i, j in enumerate(range(start_idx, min(start_idx + batch_size, data_len-2), step)):\n",
    "            row1 = data.iloc[j]\n",
    "            row2 = data.iloc[j + 1]\n",
    "            \n",
    "            # get flow data\n",
    "            img1 = preprocess_image(cv2.imread(row1['image_path']), train)\n",
    "            img2 = preprocess_image(cv2.imread(row2['image_path']), train)\n",
    "            flow = GetOpticalFlow(img1, img2)\n",
    "            f = flow\n",
    "            flow = np.transpose(flow, (2, 0, 1))\n",
    "            \n",
    "            # add gaussian noise\n",
    "            speed = np.mean([row1['speed'], row2['speed']])\n",
    "            \n",
    "            # add noise when the car is moving\n",
    "            if train and not speed:\n",
    "                speed += np.random.normal()\n",
    "            \n",
    "            image_batch[i] = flow\n",
    "            label_batch[i] = speed\n",
    "            \n",
    "        cur += 1\n",
    "        if train: image_batch, label_batch = shuffle(image_batch, label_batch)\n",
    "        x, y = torch.from_numpy(image_batch).type(torch.cuda.FloatTensor), torch.from_numpy(label_batch).type(torch.cuda.FloatTensor)\n",
    "        yield x, f, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class FlowModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FlowModel, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "        nn.Conv2d(3, 24, 5, 2),\n",
    "        nn.ELU(),\n",
    "        nn.Conv2d(24, 36, 5, 2),\n",
    "        nn.ELU(),\n",
    "        nn.Conv2d(36, 48, 5, 2),\n",
    "        nn.ELU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Conv2d(48, 64, 3),\n",
    "        nn.ELU(),\n",
    "        nn.Conv2d(64, 64, 3),\n",
    "        nn.ELU(),\n",
    "        Flatten(),\n",
    "        nn.Linear(1280, 100),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(100, 50),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(50, 10),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(10, 1))\n",
    "        \n",
    "        # initialize weights\n",
    "        self.model.apply(self.init_weights)\n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # normalize values\n",
    "        x = x / 127.5 - 1\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dl, opt):\n",
    "    criterion = nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    n_batches = 0\n",
    "    for batch_img, _, batch_label in dl:\n",
    "        batch_img.cuda()\n",
    "        model.zero_grad()\n",
    "        batch_preds = model(batch_img)\n",
    "        loss = criterion(batch_preds.squeeze(), batch_label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "        \n",
    "    return total_loss / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_validation_loss(model, val_dl):\n",
    "    n_batches = 0\n",
    "    total_loss = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    for batch_img, _, batch_label in val_dl:\n",
    "        batch_img.cuda()\n",
    "        batch_preds = model(batch_img)\n",
    "        loss = criterion(batch_preds.squeeze(), batch_label)\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "    return total_loss / n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find fastest batch size\n",
    "#for i in range(10):\n",
    "#    t0 = time.time()\n",
    "#    bs = 2**i\n",
    "#    dl = generate_training_data(train_data, batch_size=bs)\n",
    "#    train_epoch(model, dl, opt)\n",
    "#    t1 = time.time()\n",
    "#    diff = t1 - t0\n",
    "#    print('Batch size: {}, training time: {}'.format(bs, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = FlowModel().to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.05288620822876692, val_loss: 0.1673393419810704\n",
      "train_loss: 0.04539918811619282, val_loss: 0.15494962270770754\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    dl = generate_data(train_data, batch_size=bs)\n",
    "    val_dl = generate_data(val_data, batch_size=bs, train=False)\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    train_loss = train_epoch(model, dl, opt) / bs\n",
    "    \n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    val_loss = calculate_validation_loss(model, val_dl) / bs\n",
    "    print('train_loss: {}, val_loss: {}'.format(train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_path = '{}flow_model'.format(data_path)\n",
    "torch.save(model.state_dict(), model_path)\n",
    "model = FlowModel()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateVideo(fname, model, bs=32):\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    preds = []\n",
    "    batch = np.zeros((bs, 3, 66, 220))\n",
    "    \n",
    "    # get first frame\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    success, img1 = cap.read()\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "    img1 = crop(img1)\n",
    "    img1 = preprocess_image(img1)\n",
    "    currentFrame = 0\n",
    "    while success:\n",
    "        \n",
    "        # evaluate batch\n",
    "        if currentFrame % bs == 0 and currentFrame != 0:\n",
    "            batch = torch.from_numpy(batch).type(torch.cuda.FloatTensor)\n",
    "            batch_preds = model(batch.tolist())\n",
    "            preds += batch_preds\n",
    "            batch = np.zeros((bs, 3, 66, 220))\n",
    "        \n",
    "        # second frame\n",
    "        success, img2 = cap.read()\n",
    "        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "        img2 = crop(img2)\n",
    "        img2 = preprocess_image(img2)\n",
    "        \n",
    "        # make flow play nice with the model\n",
    "        flow = GetOpticalFlow(img1, img2)\n",
    "        flow = np.transpose(flow, (2, 0, 1))        \n",
    "        \n",
    "        batch[currentFrame % bs] = flow\n",
    "        img1 = img2\n",
    "        currentFrame += 1\n",
    "       \n",
    "    cap.release()\n",
    "    \n",
    "    # handle sub batch size leftovers\n",
    "    end = currentFrame % bs\n",
    "    if end != 0:\n",
    "        batch = torch.from_numpy(batch[:end]).type(torch.cuda.FloatTensor)\n",
    "        batch_preds = model(batch.tolist())\n",
    "        preds += batch_preds\n",
    "    \n",
    "    # smooth results\n",
    "    smooth_preds = gaussian_filter(preds, 10)\n",
    "    return preds, smooth_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, sp = EvaluateVideo(train_file, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
